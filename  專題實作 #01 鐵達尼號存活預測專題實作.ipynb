{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4b1d8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv')\n",
    "\n",
    "#第一個問題，本次跑的模型中，線性回歸，SVR和DBSCAN無法跑出結果，而以最初使用的邏輯回歸為基準，決策樹分類和回歸的表現並沒有比較好，但是隨機森林\n",
    "#的表現好於邏輯回歸，而SVC，KMeans和AP的表現比邏輯回歸來的差，其中AP後三次並沒有跑出結果\n",
    "\n",
    "#第2個問題本次以LogisticRegression為基準進行GridSearchCV找尋參數並設定後比較結果，得知其得分基本上不差於原本的結果(即有幾次比原本好，有幾次\n",
    "#跟原本的結果差不多)\n",
    "\n",
    "#本次最後是用pytorch來建立模型，跑出來的結果最後大概落於0.83~0.84之間，總體而言比某些模型來的好些\n",
    "\n",
    "#資料前處理與特徵提取\n",
    "pd.set_option('display.max_rows',None)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "title = pd.DataFrame()\n",
    "title['Title'] = df['Name'].map(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "Title_Dictionary={\n",
    "                  \"Capt\": \"Officer\",\n",
    "                  \"Col\": \"Officer\",\n",
    "                  \"Major\": \"Officer\",\n",
    "                  \"Jonkheer\": \"Royalty\",\n",
    "                  \"Don\": \"Royalty\",\n",
    "                  \"Sir\": \"Royalty\",\n",
    "                  \"Dr\": \"Officer\",\n",
    "                  \"Rev\": \"Officer\",\n",
    "                  \"the Countess\": \"Royalty\",\n",
    "                  \"Dona\": \"Royalty\",\n",
    "                  \"Mme\": \"Mrs\",\n",
    "                  \"Mile\": \"Miss\",\n",
    "                  \"Ms\": \"Mrs\",\n",
    "                  \"Mr\": \"Mr\",\n",
    "                  \"Mrs\": \"Mrs\",\n",
    "                  \"Miss\": \"Miss\",\n",
    "                  \"Master\": \"Master\",\n",
    "                  \"Lady\": \"Royalty\"\n",
    "}\n",
    "title['Title'] = title.Title.map(Title_Dictionary)\n",
    "title =pd.get_dummies(title.Title)\n",
    "\n",
    "def cleanTicket(ticket):\n",
    "    ticket =ticket.replace('.','')\n",
    "    ticket = ticket.replace('/','')\n",
    "    ticket = ticket.split()\n",
    "    ticket = map(lambda t: t.strip(),ticket)\n",
    "    ticket = list(filter(lambda t: not t.isdigit(), ticket))\n",
    "    if len(ticket)>0:\n",
    "        return ticket[0]\n",
    "    else:\n",
    "        return 'xxx'\n",
    "ticket = pd.DataFrame()\n",
    "ticket['Ticket'] = df['Ticket'].map(cleanTicket)\n",
    "ticket = pd.get_dummies(ticket['Ticket'],prefix='Ticket')\n",
    "\n",
    "df['ismotherchild'] = np.where((df['Age']<18) | (df['Parch'] > 0),1,0)\n",
    "df['isfatherchild'] = np.where((df['Age']<18) & (df['Parch'] > 0),1,0)\n",
    "\n",
    "family = pd.DataFrame()\n",
    "family['FamilySize']=df['Parch']+df['SibSp']+1\n",
    "family['Family_single']= family['FamilySize'].map(lambda s:1 if s ==1 else 0)\n",
    "family['Family_small']=family['FamilySize'].map(lambda s:1 if 2 <=s <= 4 else 0)\n",
    "family['Family_large']=family['FamilySize'].map(lambda s:1 if 5<= s else 0)\n",
    "\n",
    "df = pd.get_dummies(df,columns = ['Sex','Embarked'])\n",
    "df1 = pd.concat([df,title,ticket,family],axis=1)\n",
    "df_train = df1.drop(['Cabin','Ticket','Name'],axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6597aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83240223 0.8258427  0.79775281 0.80898876 0.87078652]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用邏輯回歸做分類分析\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "log = LogisticRegression(random_state=0, max_iter=3000)\n",
    "scores = cross_val_score(log, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee875bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78212291 0.78089888 0.78089888 0.76404494 0.81460674]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#用LabelEncoder方法做前處理後用邏輯回歸做分類分析\n",
    "le = LabelEncoder()\n",
    "dfe2['Embarkedl']= le.fit_transform(dfe2['Embarked'])\n",
    "dfe2 = dfe2.drop(['Embarked'],axis = 1)\n",
    "dfe2['Sexl']= le.fit_transform(dfe2['Sex'])\n",
    "dfe2 = dfe2.drop(['Sex'],axis = 1)\n",
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "log = LogisticRegression(random_state=0, max_iter=3000)\n",
    "scores = cross_val_score(log, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "844fc9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用線性回歸做分類分析(當然沒結果)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "lin = LinearRegression()\n",
    "scores = cross_val_score(lin, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "962f2e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57541899 0.81460674 0.76404494 0.79213483 0.73033708]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#用決策樹分類做分類分析\n",
    "dtc = DecisionTreeClassifier(max_depth = 3000, random_state = 0)\n",
    "scores = cross_val_score(dtc, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "60f582d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76536313 0.76404494 0.75842697 0.79775281 0.7752809 ]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用決策樹回歸做分類分析\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "dtr = DecisionTreeRegressor(max_depth = 3000, random_state = 0)\n",
    "scores = cross_val_score(dtr, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b1dd3cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78212291 0.79775281 0.82022472 0.82022472 0.83146067]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用隨機森林做分類分析\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 3000, random_state = 0)\n",
    "scores = cross_val_score(rfc, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0be69b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61452514 0.64044944 0.64606742 0.64044944 0.65168539]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用支持向量機分類做分類分析\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "svc = SVC(random_state=0, max_iter=3000)\n",
    "scores = cross_val_score(svc, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0686126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 211, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 93, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用支持向量機回歸做分類分析(當然沒結果)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "svr = SVR( max_iter=3000)\n",
    "scores = cross_val_score(svr, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5fe5f924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67039106 0.55617978 0.61235955 0.59550562 0.64606742]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用KMeans做分類分析\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "km = KMeans( n_clusters= 1, max_iter=3000,random_state = 1)\n",
    "scores = cross_val_score(km, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6946819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66480447 0.00561798 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "\n",
    "#用AP做分類分析\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "AP = AffinityPropagation( max_iter=3000,random_state = 1)\n",
    "scores = cross_val_score(AP, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3eb1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "49053721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 261, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 71, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'DBSCAN' object has no attribute 'predict'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 261, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 71, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'DBSCAN' object has no attribute 'predict'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 261, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 71, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'DBSCAN' object has no attribute 'predict'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 261, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 71, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'DBSCAN' object has no attribute 'predict'\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 261, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 71, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "AttributeError: 'DBSCAN' object has no attribute 'predict'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "\n",
    "#用DBSCAN做分類分析\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "DB = DBSCAN()\n",
    "scores = cross_val_score(DB, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fd231d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\st030\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=100, max_iter=3000, random_state=0, solver='liblinear')\n",
      "[0.83240223 0.8258427  0.79775281 0.80898876 0.87078652]\n",
      "[0.83240223 0.83146067 0.80337079 0.80898876 0.87078652]\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "#在邏輯回歸做分類分析的條件下用GridSearchCV找出最好的模型參數以跑出最理想之結果並對設定前與設定後做比較\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X= train_X\n",
    "y = train_y.values.ravel()\n",
    "\n",
    "log = LogisticRegression(random_state=0, max_iter=3000)\n",
    "param_grid={'penalty':['l1','l2' ],\n",
    "           'C': [0.001,0.01,0.1,1,10,100],\n",
    "           'solver': ['liblinear', 'saga'],\n",
    "          }\n",
    "gs = GridSearchCV(log, param_grid,cv = 5, scoring = 'accuracy')\n",
    "gs.fit(X,y)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_estimator_)\n",
    "\n",
    "log1 = LogisticRegression(penalty = 'l2',C= 1.0,solver = 'liblinear',random_state=0, max_iter=3000)\n",
    "\n",
    "scores = cross_val_score(log, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores)\n",
    "scores1 = cross_val_score(log1, train_X, train_y.values.ravel(),cv=5,scoring='accuracy')\n",
    "print(scores1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3f445573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.7636 Train Acc=0.5522 Val Loss=0.6275 Val Acc=0.6633\n",
      "Epoch 2: Train Loss=0.8864 Train Acc=0.6049 Val Loss=0.6253 Val Acc=0.6599\n",
      "Epoch 3: Train Loss=0.7076 Train Acc=0.6285 Val Loss=0.6390 Val Acc=0.6263\n",
      "Epoch 4: Train Loss=0.7079 Train Acc=0.6319 Val Loss=0.6297 Val Acc=0.6364\n",
      "Epoch 5: Train Loss=0.6792 Train Acc=0.6296 Val Loss=0.6484 Val Acc=0.6678\n",
      "Epoch 6: Train Loss=0.6672 Train Acc=0.6263 Val Loss=0.6274 Val Acc=0.6734\n",
      "Epoch 7: Train Loss=0.6430 Train Acc=0.6510 Val Loss=0.6103 Val Acc=0.6902\n",
      "Epoch 8: Train Loss=0.6440 Train Acc=0.6420 Val Loss=0.6123 Val Acc=0.7026\n",
      "Epoch 9: Train Loss=0.6268 Train Acc=0.6700 Val Loss=0.5931 Val Acc=0.6869\n",
      "Epoch 10: Train Loss=0.6144 Train Acc=0.6723 Val Loss=0.5916 Val Acc=0.6880\n",
      "Epoch 11: Train Loss=0.6191 Train Acc=0.6678 Val Loss=0.5900 Val Acc=0.6891\n",
      "Epoch 12: Train Loss=0.6255 Train Acc=0.6655 Val Loss=0.5871 Val Acc=0.6891\n",
      "Epoch 13: Train Loss=0.6107 Train Acc=0.6846 Val Loss=0.5885 Val Acc=0.6992\n",
      "Epoch 14: Train Loss=0.6176 Train Acc=0.6667 Val Loss=0.5784 Val Acc=0.6958\n",
      "Epoch 15: Train Loss=0.5979 Train Acc=0.6801 Val Loss=0.5817 Val Acc=0.7037\n",
      "Epoch 16: Train Loss=0.5921 Train Acc=0.6925 Val Loss=0.5651 Val Acc=0.7003\n",
      "Epoch 17: Train Loss=0.5869 Train Acc=0.7026 Val Loss=0.5631 Val Acc=0.7116\n",
      "Epoch 18: Train Loss=0.6009 Train Acc=0.6947 Val Loss=0.5556 Val Acc=0.7127\n",
      "Epoch 19: Train Loss=0.5933 Train Acc=0.6958 Val Loss=0.5605 Val Acc=0.7149\n",
      "Epoch 20: Train Loss=0.5811 Train Acc=0.7082 Val Loss=0.5463 Val Acc=0.7239\n",
      "Epoch 21: Train Loss=0.5811 Train Acc=0.7003 Val Loss=0.5405 Val Acc=0.7318\n",
      "Epoch 22: Train Loss=0.5770 Train Acc=0.7116 Val Loss=0.5386 Val Acc=0.7396\n",
      "Epoch 23: Train Loss=0.5646 Train Acc=0.7059 Val Loss=0.5168 Val Acc=0.7407\n",
      "Epoch 24: Train Loss=0.5652 Train Acc=0.7363 Val Loss=0.5105 Val Acc=0.7654\n",
      "Epoch 25: Train Loss=0.5524 Train Acc=0.7250 Val Loss=0.5010 Val Acc=0.7778\n",
      "Epoch 26: Train Loss=0.5571 Train Acc=0.7149 Val Loss=0.4971 Val Acc=0.7755\n",
      "Epoch 27: Train Loss=0.5308 Train Acc=0.7430 Val Loss=0.5323 Val Acc=0.7778\n",
      "Epoch 28: Train Loss=0.5254 Train Acc=0.7441 Val Loss=0.4765 Val Acc=0.7912\n",
      "Epoch 29: Train Loss=0.5315 Train Acc=0.7419 Val Loss=0.4728 Val Acc=0.8025\n",
      "Epoch 30: Train Loss=0.4895 Train Acc=0.7677 Val Loss=0.4633 Val Acc=0.7890\n",
      "Epoch 31: Train Loss=0.5006 Train Acc=0.7823 Val Loss=0.4548 Val Acc=0.7991\n",
      "Epoch 32: Train Loss=0.5072 Train Acc=0.7688 Val Loss=0.4468 Val Acc=0.8058\n",
      "Epoch 33: Train Loss=0.4940 Train Acc=0.7755 Val Loss=0.4456 Val Acc=0.8025\n",
      "Epoch 34: Train Loss=0.4756 Train Acc=0.7823 Val Loss=0.4418 Val Acc=0.8058\n",
      "Epoch 35: Train Loss=0.4899 Train Acc=0.7778 Val Loss=0.4351 Val Acc=0.8047\n",
      "Epoch 36: Train Loss=0.4802 Train Acc=0.7901 Val Loss=0.4353 Val Acc=0.8148\n",
      "Epoch 37: Train Loss=0.4718 Train Acc=0.7868 Val Loss=0.4261 Val Acc=0.8114\n",
      "Epoch 38: Train Loss=0.4874 Train Acc=0.7901 Val Loss=0.4382 Val Acc=0.8204\n",
      "Epoch 39: Train Loss=0.4728 Train Acc=0.7912 Val Loss=0.4336 Val Acc=0.8002\n",
      "Epoch 40: Train Loss=0.4501 Train Acc=0.8013 Val Loss=0.4196 Val Acc=0.8148\n",
      "Epoch 41: Train Loss=0.4807 Train Acc=0.7901 Val Loss=0.4388 Val Acc=0.8092\n",
      "Epoch 42: Train Loss=0.4734 Train Acc=0.7957 Val Loss=0.4183 Val Acc=0.8148\n",
      "Epoch 43: Train Loss=0.4530 Train Acc=0.8002 Val Loss=0.4397 Val Acc=0.8036\n",
      "Epoch 44: Train Loss=0.4735 Train Acc=0.7946 Val Loss=0.4285 Val Acc=0.8137\n",
      "Epoch 45: Train Loss=0.4500 Train Acc=0.8126 Val Loss=0.4168 Val Acc=0.8171\n",
      "Epoch 46: Train Loss=0.4513 Train Acc=0.8114 Val Loss=0.4182 Val Acc=0.8114\n",
      "Epoch 47: Train Loss=0.4598 Train Acc=0.7969 Val Loss=0.4155 Val Acc=0.8148\n",
      "Epoch 48: Train Loss=0.4662 Train Acc=0.7957 Val Loss=0.4431 Val Acc=0.7980\n",
      "Epoch 49: Train Loss=0.4481 Train Acc=0.7991 Val Loss=0.4101 Val Acc=0.8148\n",
      "Epoch 50: Train Loss=0.4575 Train Acc=0.8103 Val Loss=0.4139 Val Acc=0.8204\n",
      "Epoch 51: Train Loss=0.4499 Train Acc=0.7969 Val Loss=0.4202 Val Acc=0.8171\n",
      "Epoch 52: Train Loss=0.4482 Train Acc=0.8047 Val Loss=0.4093 Val Acc=0.8215\n",
      "Epoch 53: Train Loss=0.4491 Train Acc=0.8002 Val Loss=0.4121 Val Acc=0.8092\n",
      "Epoch 54: Train Loss=0.4459 Train Acc=0.8081 Val Loss=0.4056 Val Acc=0.8215\n",
      "Epoch 55: Train Loss=0.4435 Train Acc=0.8204 Val Loss=0.4072 Val Acc=0.8227\n",
      "Epoch 56: Train Loss=0.4364 Train Acc=0.8114 Val Loss=0.4073 Val Acc=0.8193\n",
      "Epoch 57: Train Loss=0.4381 Train Acc=0.8092 Val Loss=0.4113 Val Acc=0.8137\n",
      "Epoch 58: Train Loss=0.4580 Train Acc=0.8070 Val Loss=0.4296 Val Acc=0.8204\n",
      "Epoch 59: Train Loss=0.4407 Train Acc=0.8193 Val Loss=0.4088 Val Acc=0.8249\n",
      "Epoch 60: Train Loss=0.4477 Train Acc=0.7991 Val Loss=0.4090 Val Acc=0.8294\n",
      "Epoch 61: Train Loss=0.4354 Train Acc=0.8260 Val Loss=0.3958 Val Acc=0.8305\n",
      "Epoch 62: Train Loss=0.4324 Train Acc=0.8103 Val Loss=0.4053 Val Acc=0.8238\n",
      "Epoch 63: Train Loss=0.4327 Train Acc=0.8193 Val Loss=0.4054 Val Acc=0.8126\n",
      "Epoch 64: Train Loss=0.4253 Train Acc=0.8204 Val Loss=0.3997 Val Acc=0.8238\n",
      "Epoch 65: Train Loss=0.4286 Train Acc=0.8193 Val Loss=0.4006 Val Acc=0.8305\n",
      "Epoch 66: Train Loss=0.4284 Train Acc=0.8215 Val Loss=0.3918 Val Acc=0.8260\n",
      "Epoch 67: Train Loss=0.4183 Train Acc=0.8227 Val Loss=0.4014 Val Acc=0.8272\n",
      "Epoch 68: Train Loss=0.4270 Train Acc=0.8182 Val Loss=0.3924 Val Acc=0.8305\n",
      "Epoch 69: Train Loss=0.4431 Train Acc=0.8081 Val Loss=0.4054 Val Acc=0.8283\n",
      "Epoch 70: Train Loss=0.4147 Train Acc=0.8227 Val Loss=0.3912 Val Acc=0.8305\n",
      "Epoch 71: Train Loss=0.4283 Train Acc=0.8193 Val Loss=0.4082 Val Acc=0.8283\n",
      "Epoch 72: Train Loss=0.4394 Train Acc=0.8025 Val Loss=0.4014 Val Acc=0.8384\n",
      "Epoch 73: Train Loss=0.4323 Train Acc=0.8171 Val Loss=0.3919 Val Acc=0.8373\n",
      "Epoch 74: Train Loss=0.4347 Train Acc=0.8193 Val Loss=0.4094 Val Acc=0.8227\n",
      "Epoch 75: Train Loss=0.4149 Train Acc=0.8283 Val Loss=0.4019 Val Acc=0.8227\n",
      "Epoch 76: Train Loss=0.4342 Train Acc=0.8227 Val Loss=0.3895 Val Acc=0.8260\n",
      "Epoch 77: Train Loss=0.4200 Train Acc=0.8294 Val Loss=0.3883 Val Acc=0.8361\n",
      "Epoch 78: Train Loss=0.4235 Train Acc=0.8260 Val Loss=0.4007 Val Acc=0.8204\n",
      "Epoch 79: Train Loss=0.4333 Train Acc=0.8249 Val Loss=0.3944 Val Acc=0.8339\n",
      "Epoch 80: Train Loss=0.4304 Train Acc=0.8137 Val Loss=0.3887 Val Acc=0.8350\n",
      "Epoch 81: Train Loss=0.4121 Train Acc=0.8305 Val Loss=0.3869 Val Acc=0.8395\n",
      "Epoch 82: Train Loss=0.3992 Train Acc=0.8462 Val Loss=0.3841 Val Acc=0.8395\n",
      "Epoch 83: Train Loss=0.4102 Train Acc=0.8171 Val Loss=0.3833 Val Acc=0.8328\n",
      "Epoch 84: Train Loss=0.4110 Train Acc=0.8294 Val Loss=0.3829 Val Acc=0.8429\n",
      "Epoch 85: Train Loss=0.4014 Train Acc=0.8148 Val Loss=0.3836 Val Acc=0.8406\n",
      "Epoch 86: Train Loss=0.3916 Train Acc=0.8316 Val Loss=0.3767 Val Acc=0.8474\n",
      "Epoch 87: Train Loss=0.4146 Train Acc=0.8260 Val Loss=0.3932 Val Acc=0.8283\n",
      "Epoch 88: Train Loss=0.4024 Train Acc=0.8350 Val Loss=0.3883 Val Acc=0.8406\n",
      "Epoch 89: Train Loss=0.3970 Train Acc=0.8361 Val Loss=0.3739 Val Acc=0.8418\n",
      "Epoch 90: Train Loss=0.3991 Train Acc=0.8361 Val Loss=0.4091 Val Acc=0.8204\n",
      "Epoch 91: Train Loss=0.4157 Train Acc=0.8294 Val Loss=0.3837 Val Acc=0.8418\n",
      "Epoch 92: Train Loss=0.4096 Train Acc=0.8328 Val Loss=0.3865 Val Acc=0.8361\n",
      "Epoch 93: Train Loss=0.4139 Train Acc=0.8260 Val Loss=0.3753 Val Acc=0.8361\n",
      "Epoch 94: Train Loss=0.3935 Train Acc=0.8328 Val Loss=0.3765 Val Acc=0.8451\n",
      "Epoch 95: Train Loss=0.3952 Train Acc=0.8249 Val Loss=0.3729 Val Acc=0.8418\n",
      "Epoch 96: Train Loss=0.4015 Train Acc=0.8305 Val Loss=0.3680 Val Acc=0.8418\n",
      "Epoch 97: Train Loss=0.3964 Train Acc=0.8283 Val Loss=0.3730 Val Acc=0.8406\n",
      "Epoch 98: Train Loss=0.3997 Train Acc=0.8361 Val Loss=0.3704 Val Acc=0.8418\n",
      "Epoch 99: Train Loss=0.4014 Train Acc=0.8373 Val Loss=0.3744 Val Acc=0.8440\n",
      "Epoch 100: Train Loss=0.4064 Train Acc=0.8339 Val Loss=0.3894 Val Acc=0.8350\n"
     ]
    }
   ],
   "source": [
    "columns_X = set(df_train.columns) - {'Survived'}\n",
    "columns_y = ['Survived']\n",
    "\n",
    "\n",
    "train_X = df_train[columns_X]\n",
    "train_y = df_train[columns_y]\n",
    "#利用pytorch建立模型逕行分類分析並得出模型的精準度\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.X=df.drop('Survived',axis =1).values\n",
    "        self.y = df['Survived'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TitanicModel, self).__init__()\n",
    "        self.fc1=nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.fc3 = nn.Linear(32,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout= nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def train(model,train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for i ,(inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        predicted = torch.argmax(outputs,1)\n",
    "        train_acc += torch.sum(predicted == targets.data)\n",
    "        \n",
    "    train_loss = train_loss/ len(train_loader.dataset)\n",
    "    train_acc = train_acc/len(train_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "    \n",
    "def validate(model, val_loader,  criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs,targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = torch.argmax(outputs,1)\n",
    "            val_acc += torch.sum(predicted == targets.data)\n",
    "    val_loss = val_loss/ len(val_loader.dataset)\n",
    "    val_acc = val_acc/ len(val_loader.dataset)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TitanicModel(input_dim = 54).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr =0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_dataset = TitanicDataset(df_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32,shuffle = True)\n",
    "val_dataset = TitanicDataset(df_train)\n",
    "val_loader =  DataLoader(val_dataset, batch_size = 32,shuffle = False)\n",
    "for epoch in range(100):\n",
    "    train_loss, train_acc=train(model,train_loader,optimizer,criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch +1}: Train Loss={train_loss:.4f} Train Acc={train_acc:.4f} Val Loss={val_loss:.4f} Val Acc={val_acc:.4f}\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9875b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
